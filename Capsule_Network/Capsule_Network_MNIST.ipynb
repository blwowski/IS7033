{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Capsnet: \"Dynamic Routing Between Capsules\"</h1>\n",
    "<h4><span style=\"text-decoration: underline;\">Original Paper:</span> Geoffrey E. Hinton,&nbsp;Sara Sabour,&nbsp; Nicholas Frosst</h4>\n",
    "<h4><span style=\"text-decoration: underline;\">Notebook Author:</span>&nbsp; Brandon Lwowski</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>I. Introduction</h2>\n",
    "<p>Geoffrey Hinton and his colleagues developed a new architecture for neural nets, called Capsule Networks, to tackle some of the negative issues present with the traditional CNN. The Convolutional Neural Network is commonly used in tasks such as computer vision and text classification. VGG-16, Inception, and ResNet-50 are all architectures that are extremely successful in the domain of computer vision and all use multiple convolutional layers in their networks.</p>\n",
    "<p>Even with the large amount of success that CNN's have earned, there are drawbacks present that limit their overall ability. CNN's do not store spatial or orientational relationships between features. The most common example is the human face. As long as the image has 2 eyes, a nose, and a mouth, the CNN will classify it a face, regardless of if the mouth is above the eyes, or the nose is by the ears.&nbsp;</p>\n",
    "<p>The Capsule Network was Hinton&rsquo;s attempt to fix these known issues of CNN's. The \"capsules\" in this architecture learn spatial and orientational features, which will be discussed later in this notebook. In this notebook you will see my implementation of a Capsule Network on the MNIST data set. The network is trained on data that has not been augmented and tested on images that have been scaled and rotated. You will see that the CapsNet does well on the scaled data but, still struggles to solve the rotational invariance issue with traditional CNNs.</p>\n",
    "<img src = \"./images/capsnet.png\">\n",
    "<h2>II. Background</h2>\n",
    "<p>&nbsp;</p>\n",
    "<p>What are Capsules? You can find a detailed explanation in Hinton&rsquo;s first paper \"<a href=\"http://www.cs.toronto.edu/~fritz/absps/transauto6.pdf\">Transforming Auto-encoders</a>\" but I will do my best to paraphrase here. A capsule is a set of neurons that produce a vector. This differs from a typical neural network, where the output is a scalar. This vector can represent the size, orientation, or even the hue of the image once trained.</p>\n",
    "<p>&nbsp;</p>\n",
    "<img src = \"./images/capsule.png\">\n",
    "<p>In the image above you will see 2 different types of capsules. The red capsules are created using 3 neurons and the green capsules are created using 4 neurons. The red capsules are used as recognition units and the green capsules are used as generation units (This will be discussed further down in the notebook).&nbsp; Recognition units, similar to the hidden later in a general artificial neural network, are used to compute the X-position, Y-position and the probability that the visual feature is present in the input image. The generation units receive the X-position plus the change in X and the Y-position plus the change in Y and then are multiplied by the probability to generate the actual output. The distance between the actual output and target output are then calculated and used to adjust the capsules weights. By multiplying the output of the generation units by the probability, inactive capsules will not affect the actual output.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>III. Implementation</h2>\n",
    "<p>Below you will find my pytorch implementation of capsule networks and the dynamic routing algorithm provided by Hinton.&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries\n",
    "\n",
    "### pytorch libraries needed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np               ### Matrix Math\n",
    "import matplotlib.pyplot as plt  ### Data visualizations\n",
    "\n",
    "from tqdm import tqdm            ### Create progress bar\n",
    "import gc                        ### Garbage collect to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0c47cf4310>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hyperparameters\n",
    "USE_CUDA = True if torch.cuda.is_available() else False\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 30            \n",
    "LEARNING_RATE = 0.0001\n",
    "MOMENTUM = 0.7\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>III(a). Data and Data Analysis</h2>\n",
    "<p>The following four functions are used to create train and test data. For this experiment of the capsule network, I plan to train the model on data that has not been augmented. It will be trained on the original 29x29 MNIST data set. The goal of this notebook is to investigate how well the model can classify MNIST data that has been rotated or scaled. The <font face=\"courier\">test_loader</font> is a base line; these images are not augmented.  <font face=\"courier\">test_loader_rotate</font> is a test set of MNIST images randomly rotated -75 degrees to 75 degrees. Lastly, the  <font face=\"courier\">test_loader_scale_half</font> was resized, so the image is half the size and padded to match the 28x28 dimensions. Below those 4 functions you will find examples of training set, test set original, test set rotated, and test set scaled&nbsp;</p>\n",
    "<img src = \"./images/MNIST.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get MNIST Data\n",
    "\n",
    "#train = True pulls from training set train = False pulls from testing data\n",
    "#Compose() chains multiple transformations together\n",
    "#ToTensor() transforms PIL image or numpy array to torch tensor\n",
    "#Normalize() normalize a tensor image with mean and standard deviation (mean, std)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.Resize((28, 28)),\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.Resize((28, 28)),\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_loader_rotate = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.RandomRotation((-75,75)),\n",
    "                               torchvision.transforms.Resize((28, 28)),\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_loader_scale_half = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                                transforms.Resize(20),\n",
    "                                transforms.Pad(padding=4, padding_mode='edge'),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "Example Shape: torch.Size([128, 1, 28, 28])\n",
      "Target Shape : torch.Size([128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/home/ubuntu/.local/lib/python3.7/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Train Data\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "print (\"Index:\", batch_idx)\n",
    "print (\"Example Shape:\", example_data.shape)\n",
    "print (\"Target Shape :\", example_targets.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "for i in range(6):\n",
    "    plt.subplot(1,6, i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "Example Shape: torch.Size([128, 1, 28, 28])\n",
      "Target Shape : torch.Size([128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/home/ubuntu/.local/lib/python3.7/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Test Data Rotate\n",
    "examples = enumerate(test_loader_rotate)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "print (\"Index:\", batch_idx)\n",
    "print (\"Example Shape:\", example_data.shape)\n",
    "print (\"Target Shape :\", example_targets.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "for i in range(6):\n",
    "    plt.subplot(1,6, i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "Example Shape: torch.Size([128, 1, 28, 28])\n",
      "Target Shape : torch.Size([128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/home/ubuntu/.local/lib/python3.7/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Test Data Scale\n",
    "examples = enumerate(test_loader_scale_half)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "print (\"Index:\", batch_idx)\n",
    "print (\"Example Shape:\", example_data.shape)\n",
    "print (\"Target Shape :\", example_targets.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "for i in range(6):\n",
    "    plt.subplot(1,6, i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31010"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>III(b). Design</h2>\n",
    "<p>The topology of a Capsule Network has 4 major components that make up the CapsNet architecture. The convolutional layer, primary caps layer, digit caps layer, and the decoder.&nbsp; Each of the 4 components will have a detailed explanation further down in the notebook.&nbsp;</p>\n",
    "<p>In order to discuss how the CapsNet works, it is important to understand the Hinton&rsquo;s new activation function, called the squash function, the loss function for the CapsNet, and the Dynamic Routing algorithm used in his paper.</p>\n",
    "<p>Below you will find the equation created by Hinton called the squash function. Typically, in CNNs, you will see activation functions like relu in order to create non-linearity in the network. The objective of the squash function is to take a vector as an input and \"squash\" it to have a length of no more than 1. By squashing the vector, it can now be interpreted as a probability that the feature is present in the image.</p>\n",
    "<p>Looking at the formula it is key to note that the subscript 'j' represents capsule j and s <sub>j</sub> is the input vector.&nbsp;</p>\n",
    "<img src = \"./images/squash.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(s_j):\n",
    "    squared_norm = (s_j ** 2).sum(-1, keepdim=True)\n",
    "    v_j = squared_norm * s_j / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
    "    return v_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Margin Loss from CapsNet Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./images/marginloss.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The next important part of the CapsNet to discuss is the loss function used by Hinton in his paper. He calls it the \"margin loss for digit existence\". In order to understand this complicated equation, it is easier to break it into pieces. What the margin loss function is trying to do is calculate the loss for every class \"k\". The term L<sub>k</sub>is the calculated loss for class k. The losses for each k will be summed and averaged to calculate the final loss for the current batch.&nbsp;</p>\n",
    "<p>The next import part of the equation in T<sub>k</sub>.   T<sub>k</sub> is the correct label for the input v<sub>k</sub>. T<sub>k</sub> will always equal 1 if DigitCap is correct and will equal 0 when it is incorrect.&nbsp;</p>\n",
    "<p>The max functions can be defined as relu activations. The max function on the left will produce a 0 loss when the prediction has a greater probability than 0.9 and the max function on the right will produce a 0 loss with a probability less than 0.1.&nbsp;</p>\n",
    "<p>The last piece to discuss it the lambda times 1 - T<sub>c</sub>. When T<sub>c</sub> is correct then the entire expression goes to 0. When T<sub>c</sub> is incorrect the expression goes to lambda. In Hinton&rsquo;s implementation, he uses a lambda value of 0.5.&nbsp;</p>\n",
    "<p>To simplify the equation, the left side of the equation will be calculated if the prediction is correct and the right side of the equation will be calculated if the prediction is incorrect.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(v_k, T_k, size_average=True):\n",
    "        #v_k shape = [batch_size, number of digits, length of digit caps, 1 batch]\n",
    "        batch_size = v_k.size(0)\n",
    "        \n",
    "        # get the norm of v_k\n",
    "        v_k_norm = torch.sqrt((v_k ** 2).sum(dim=2, keepdim=True))\n",
    "        \n",
    "        # 0.9 is given for m+ and 0.1 is given for m- from the Dynamic Routing paper \n",
    "        left = F.relu(0.9 - v_k_norm).view(batch_size, -1)\n",
    "        right = F.relu(v_k_norm - 0.1).view(batch_size, -1)\n",
    "        \n",
    "        # 0.5 is given for lamda from the Dynamic Routing paper\n",
    "        loss = T_k * left + 0.5 * (1.0 - T_k) * right\n",
    "        loss = loss.sum(dim=1).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 1 = Convolutional Layer\n",
    "<img src = \"./images/capsnet_conv.png\">\n",
    "<p>Input = 28x28 image (one color channel)</p>\n",
    "<p>Number of Kernals = 256</p>\n",
    "<p>Kernal Size = 9x9</p>\n",
    "<p>Stride = 1</p>\n",
    "<p>Output = 20x20x256</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=256, kernel_size=9):\n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              stride=1\n",
    "                              )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.conv(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2 = Primary Caps Layer\n",
    "<img src = \"./images/capsnet_PC.png\">\n",
    "<p>Input = 20x20x256 tensor</p>\n",
    "<p> Number of Capsules = 32</p>\n",
    "<p>Kernal Size = 9x9x256</p>\n",
    "<p>Stride = 2</p>\n",
    "<p>Output = 6x6x9x32 tensor</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32, kernel_size=9, num_routes=32 * 6 * 6):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "        self.num_routes = num_routes\n",
    "        self.capsules = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=0)\n",
    "            for _ in range(num_capsules)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = [capsule(x) for capsule in self.capsules]\n",
    "        u = torch.stack(u, dim=1)\n",
    "        u = u.view(x.size(0), self.num_routes, -1)\n",
    "        return squash(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 3 = Digit Caps Layer\n",
    "<img src = \"./images/capsnet_DC.png\">\n",
    "<p>Input = 6x6x8x32 tensor</p>\n",
    "<p>Number of Capsules = 10 </p>\n",
    "\n",
    "<p>Output = 16x10 matrix</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=10, num_routes=32 * 6 * 6, in_channels=8, out_channels=16):\n",
    "        super(DigitCaps, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.num_routes = num_routes\n",
    "        self.num_capsules = num_capsules\n",
    "\n",
    "        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
    "\n",
    "        W = torch.cat([self.W] * batch_size, dim=0)\n",
    "        u_hat = torch.matmul(W, x)\n",
    "\n",
    "        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n",
    "        if USE_CUDA:\n",
    "            b_ij = b_ij.cuda()\n",
    "\n",
    "        num_iterations = 3\n",
    "        for iteration in range(num_iterations):\n",
    "            c_ij = F.softmax(b_ij, dim=1)\n",
    "            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
    "\n",
    "            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
    "            v_j = squash(s_j)\n",
    "\n",
    "            if iteration < num_iterations - 1:\n",
    "                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n",
    "                b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n",
    "\n",
    "        return v_j.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "<p>Input =&nbsp;16-dimensional vector from the Digit Capsule Layer</p>\n",
    "<p>Output = 28x28 reconstructed image</p>\n",
    "<p>Loss Function =&nbsp;&nbsp;Euclidean distance between the reconstructed image and the input image&nbsp;</p>\n",
    "\n",
    "### Layer 4 = Fully Connected 1\n",
    "<p>Input =&nbsp;16x10 flattened (160 nodes)</p>\n",
    "<p>Output = 512 nodes</p>\n",
    "\n",
    "### Layer 5 = Fully Connected 2\n",
    "<p>Input 512 nodes</p>\n",
    "<p>Output = 1024 nodes</p>\n",
    "\n",
    "### Layer 6 = Fully Connected 3\n",
    "<p>Input 1024 nodes</p>\n",
    "<p>Output = 784 nodes (28x28)</p>\n",
    "\n",
    "<img src = \"./images/decoder.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_width=28, input_height=28, input_channel=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.input_channel = input_channel\n",
    "        self.reconstraction_layers = nn.Sequential(\n",
    "            nn.Linear(16 * 10, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, self.input_height * self.input_height * self.input_channel),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, data):\n",
    "        classes = torch.sqrt((x ** 2).sum(2))\n",
    "        classes = F.softmax(classes, dim=0)\n",
    "\n",
    "        _, max_length_indices = classes.max(dim=1)\n",
    "        masked = Variable(torch.sparse.torch.eye(10))\n",
    "        if USE_CUDA:\n",
    "            masked = masked.cuda()\n",
    "        masked = masked.index_select(dim=0, index=Variable(max_length_indices.squeeze(1).data))\n",
    "        t = (x * masked[:, :, None, None]).view(x.size(0), -1)\n",
    "        reconstructions = self.reconstraction_layers(t)\n",
    "        reconstructions = reconstructions.view(-1, self.input_channel, self.input_width, self.input_height)\n",
    "        return reconstructions, masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Entire Capsule Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNet(nn.Module):\n",
    "    def __init__(self, config=None):\n",
    "        super(CapsNet, self).__init__()\n",
    "        if config:\n",
    "            self.conv_layer = ConvLayer(config.cnn_in_channels, config.cnn_out_channels, config.cnn_kernel_size)\n",
    "            self.primary_capsules = PrimaryCaps(config.pc_num_capsules, config.pc_in_channels, config.pc_out_channels,\n",
    "                                                config.pc_kernel_size, config.pc_num_routes)\n",
    "            self.digit_capsules = DigitCaps(config.dc_num_capsules, config.dc_num_routes, config.dc_in_channels,\n",
    "                                            config.dc_out_channels)\n",
    "            self.decoder = Decoder(config.input_width, config.input_height, config.cnn_in_channels)\n",
    "        else:\n",
    "            self.conv_layer = ConvLayer()\n",
    "            self.primary_capsules = PrimaryCaps()\n",
    "            self.digit_capsules = DigitCaps()\n",
    "            self.decoder = Decoder()\n",
    "\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, data):\n",
    "        output = self.digit_capsules(self.primary_capsules(self.conv_layer(data)))\n",
    "        reconstructions, masked = self.decoder(output, data)\n",
    "        return output, reconstructions, masked\n",
    "\n",
    "    def loss(self, data, x, target, reconstructions):\n",
    "        return margin_loss(x, target) + self.reconstruction_loss(data, reconstructions)\n",
    "\n",
    "\n",
    "    def reconstruction_loss(self, data, reconstructions):\n",
    "        loss = self.mse_loss(reconstructions.view(reconstructions.size(0), -1), data.view(reconstructions.size(0), -1))\n",
    "        return loss * 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Loops for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, epoch):\n",
    "    capsule_net = model\n",
    "    capsule_net.train()\n",
    "    n_batch = len(list(enumerate(train_loader)))\n",
    "    total_loss = 0\n",
    "    for batch_id, (data, target) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "        target = torch.sparse.torch.eye(10).index_select(dim=0, index=target)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        if USE_CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, reconstructions, masked = capsule_net(data)\n",
    "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct = sum(np.argmax(masked.data.cpu().numpy(), 1) == np.argmax(target.data.cpu().numpy(), 1))\n",
    "        train_loss = loss.data\n",
    "        total_loss += train_loss\n",
    "        if batch_id % 100 == 0:\n",
    "            tqdm.write(\"Epoch: [{}/{}], Batch: [{}/{}], train accuracy: {:.6f}, loss: {:.6f}\".format(\n",
    "                epoch,\n",
    "                N_EPOCHS,\n",
    "                batch_id + 1,\n",
    "                n_batch,\n",
    "                correct / float(BATCH_SIZE),\n",
    "                train_loss / float(BATCH_SIZE)\n",
    "                ))\n",
    "    tqdm.write('Epoch: [{}/{}], train loss: {:.6f}'.format(epoch,N_EPOCHS,total_loss / len(train_loader.dataset)))\n",
    "    \n",
    "def test(capsule_net, test_loader, epoch, name):\n",
    "    capsule_net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for batch_id, (data, target) in enumerate(test_loader):\n",
    "\n",
    "        target = torch.sparse.torch.eye(10).index_select(dim=0, index=target)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        if USE_CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output, reconstructions, masked = capsule_net(data)\n",
    "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
    "\n",
    "        test_loss += loss.data\n",
    "        correct += sum(np.argmax(masked.data.cpu().numpy(), 1) ==\n",
    "                       np.argmax(target.data.cpu().numpy(), 1))\n",
    "\n",
    "    tqdm.write(\n",
    "        \"Epoch: [{}/{}], test accuracy {}: {:.6f}, loss: {:.6f}\".format(epoch, N_EPOCHS, str(name), correct / len(test_loader.dataset),\n",
    "                                                                  test_loss / len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "capsule_net = CapsNet()\n",
    "\n",
    "if USE_CUDA:\n",
    "    capsule_net = capsule_net.cuda()\n",
    "#capsule_net = capsule_net.module\n",
    "\n",
    "optimizer = torch.optim.Adam(capsule_net.parameters())\n",
    "\n",
    "for e in range(1, N_EPOCHS + 1):\n",
    "    train(capsule_net, optimizer, train_loader, e)\n",
    "    test(capsule_net, test_loader, e, \"NORMAL TEST\")\n",
    "    test(capsule_net, test_loader_rotate, e, \"ROTATED TEST\")\n",
    "    test(capsule_net, test_loader_scale_half, e, \"SCALE TEST\")\n",
    "\n",
    "\n",
    "torch.save(capsule_net.state_dict(), './capsnet_trained.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sources</h2>\n",
    "<p>1.&nbsp;<a href=\"https://arxiv.org/pdf/1710.09829.pdf\">Dynamic Routing Between Capsules</a>&nbsp;</p>\n",
    "<p>2. <a href=\"https://openreview.net/pdf?id=HJWLfGWRb\">Matrix Capsules with EM Routing</a></p>\n",
    "<p>3.&nbsp;<a href=\"http://www.cs.toronto.edu/~fritz/absps/transauto6.pdf\">Transforming Auto-encoders</a></p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
