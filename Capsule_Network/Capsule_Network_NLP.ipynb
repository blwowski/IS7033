{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Capsule Network on the classic IMDB Sentiment</h2>\n",
    "<p>The goal of this notebook is to explore the Capsule Network on the classic IMDB Sentiment Analysis dataset. I would like to investigate how well the CapsNet does on NLP task such as sentiment analysis and compare it to the state of the art.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data and Prepare it for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Settings to tokenize sentences and convert labels to torch floats\n",
    "TEXT = data.Field(tokenize = 'spacy')\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "### Get test/train split for torchtext\n",
    "train, test = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 25000\n",
      "Number of training examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print('Number of training examples: {}'.format(len(train)))\n",
    "print('Number of training examples: {}'.format(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['This', 'movie', 'had', 'me', 'smiling', 'from', 'beginning', 'to', 'end', ',', 'partly', 'at', 'the', 'humor', ',', 'partly', 'at', 'Meg', 'Ryan', '(', 'this', 'is', 'the', 'perfect', 'character', 'for', 'her', ')', ',', 'and', 'always', 'because', 'it', \"'s\", 'just', 'one', 'of', 'the', 'best', 'feel', '-', 'good', 'movies', 'I', \"'ve\", 'seen', '.', 'Hopefully', 'the', 'DVD', 'will', 'be', 'out', 'soon', '.'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "### Example Review and Label\n",
    "print(vars(train.examples[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vocabulary\n",
    "TEXT.build_vocab(train)\n",
    "LABEL.build_vocab(train)\n",
    "vocab_dict = dict(TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wv_matrix(vocab_dict):\n",
    "    print ('... Loading Word Vectors')\n",
    "    word_vectors = KeyedVectors.load_word2vec_format(\"./models/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "    wv_matrix = []\n",
    "    count = 0\n",
    "    \n",
    "    for each in vocab_dict.items():\n",
    "        count += 1\n",
    "        \n",
    "        word = str(each[0])\n",
    "        index = int(each[1])\n",
    "        \n",
    "        if word in word_vectors.vocab:\n",
    "            wv_matrix.append(word_vectors.word_vec(word))\n",
    "        else:\n",
    "            wv_matrix.append(np.random.uniform(-0.01, 0.01, 300).astype(\"float32\"))\n",
    "        \n",
    "        if count %10000 == 0:\n",
    "            print (\"On Index {}\".format(count))\n",
    "            \n",
    "    ### Add Unknown Token\n",
    "    wv_matrix.append(np.random.uniform(-0.01, 0.01, 300).astype(\"float32\"))\n",
    "    ### Add Pad Token\n",
    "    wv_matrix.append(np.zeros(300).astype(\"float32\"))\n",
    "    print ('... Finished Creating Matrix')\n",
    "    return np.array(wv_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Loading Word Vectors\n",
      "On Index 10000\n",
      "On Index 20000\n",
      "On Index 30000\n",
      "On Index 40000\n",
      "On Index 50000\n",
      "On Index 60000\n",
      "On Index 70000\n",
      "On Index 80000\n",
      "On Index 90000\n",
      "On Index 100000\n",
      "On Index 110000\n",
      "On Index 120000\n",
      "... Finished Creating Matrix\n"
     ]
    }
   ],
   "source": [
    "wv_matrix = create_wv_matrix(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if wv_matrix represents googles word2vec\n",
    "word = \"check\"\n",
    "word_array1 = wv_matrix[vocab_dict[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vectors = KeyedVectors.load_word2vec_format(\"./models/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "word_array2 =word_vectors.word_vec(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(word_array1 == word_array2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        ### Convolution Layer 1\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 300, 300)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=32,            # n_filters\n",
    "                kernel_size=7,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=3,                  # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (32, 300, 300)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # (300-2 / 2) choose max value in 2x2 area, output shape (32, 150, 150)\n",
    "        )\n",
    "        \n",
    "        ### Convolution Layer 2\n",
    "        self.conv2 = nn.Sequential(        # input shape (32, 150, 150)\n",
    "            nn.Conv2d(32, 64, 7, 1, 3),     # output shape (64, 150, 150)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (64, 75, 75)\n",
    "        )\n",
    "            \n",
    "        ### Fully Connected Layer 3\n",
    "        self.FC1 = nn.Linear(64 * 75 * 75, 150000)\n",
    "        \n",
    "        ### Fully Connected Layer 4\n",
    "        self.FC2 = nn.Linear(150000, 75000)\n",
    "        \n",
    "        # Output 2 classes\n",
    "        self.out = nn.Linear(75000, 1)\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2\n",
    "        x = self.FC1(x)\n",
    "        x = self.FC2(x)\n",
    "        output = self.out(x)\n",
    "        \n",
    "        return output, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
